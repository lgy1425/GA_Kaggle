{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# DRAGONS\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cat\n",
    "# plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# pandas / plt options\n",
    "pd.options.display.max_columns = 999\n",
    "plt.rcParams['figure.figsize'] = (14, 7)\n",
    "font = {'family' : 'verdana',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 14}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import json\n",
    "# garbage collector\n",
    "import gc\n",
    "gc.enable()\n",
    "from pandas.io.json import json_normalize\n",
    "import pickle\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903653, 55) (804684, 53)\n"
     ]
    }
   ],
   "source": [
    "def load_df(csv_path):\n",
    "    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    ans = pd.DataFrame()\n",
    "    dfs = pd.read_csv(csv_path, sep=',',usecols=lambda col: col not in [\"hits\"],\n",
    "            converters={column: json.loads for column in JSON_COLUMNS}, \n",
    "            dtype={'fullVisitorId': 'str'}, # Important!!\n",
    "            chunksize=100000)\n",
    "    for df in dfs:\n",
    "        df.reset_index(drop = True,inplace = True)\n",
    "        for column in JSON_COLUMNS:\n",
    "            column_as_df = json_normalize(df[column])\n",
    "            column_as_df.columns = [column+\".\"+subcolumn for subcolumn in column_as_df.columns]\n",
    "            df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n",
    "\n",
    "        #print(f\"Loaded {os.path.basename(csv_path)}. Shape: {df.shape}\")\n",
    "#         use_df = df[features]\n",
    "#         del df\n",
    "        gc.collect()\n",
    "        ans = pd.concat([ans,df], axis=0).reset_index(drop=True)\n",
    "        #print(ans.shape)\n",
    "    return ans\n",
    "\n",
    "train = load_df(\"/home/mediwhale-2/GAC_kaggle/data/train.csv\")\n",
    "test= load_df(\"/home/mediwhale-2/GAC_kaggle/data/test.csv\")\n",
    "\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"totals.transactionRevenue\"] = train[\"totals.transactionRevenue\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.fillna(0, inplace=True)\n",
    "test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encode the categorical variables and convert the numerical variables to float\n",
    "cat_cols = [\"channelGrouping\", \"device.browser\", \n",
    "            \"device.deviceCategory\", \"device.operatingSystem\", \n",
    "            \"geoNetwork.city\", \"geoNetwork.continent\", \n",
    "            \"geoNetwork.country\", \"geoNetwork.metro\",\n",
    "            \"geoNetwork.networkDomain\", \"geoNetwork.region\", \n",
    "            \"geoNetwork.subContinent\", \"trafficSource.adContent\", \n",
    "            \"trafficSource.adwordsClickInfo.adNetworkType\", \n",
    "            \"trafficSource.adwordsClickInfo.gclId\", \n",
    "            \"trafficSource.adwordsClickInfo.page\", \n",
    "            \"trafficSource.adwordsClickInfo.slot\", \"trafficSource.campaign\",\n",
    "            \"trafficSource.keyword\", \"trafficSource.medium\", \n",
    "            \"trafficSource.referralPath\", \"trafficSource.source\",\n",
    "            'trafficSource.adwordsClickInfo.isVideoAd', 'trafficSource.isTrueDirect']\n",
    "\n",
    "num_cols = [\"totals.hits\", \"totals.pageviews\", \"visitNumber\", 'totals.bounces',  'totals.newVisits']   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"hits_per_pageviews\"] = train[\"totals.hits\"] / train[\"totals.pageviews\"]\n",
    "\n",
    "num_cols = num_cols + [\"hits_per_pageviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channelGrouping\n",
      "device.browser\n",
      "device.deviceCategory\n",
      "device.operatingSystem\n",
      "geoNetwork.city\n",
      "geoNetwork.continent\n",
      "geoNetwork.country\n",
      "geoNetwork.metro\n",
      "geoNetwork.networkDomain\n",
      "geoNetwork.region\n",
      "geoNetwork.subContinent\n",
      "trafficSource.adContent\n",
      "trafficSource.adwordsClickInfo.adNetworkType\n",
      "trafficSource.adwordsClickInfo.gclId\n",
      "trafficSource.adwordsClickInfo.page\n",
      "trafficSource.adwordsClickInfo.slot\n",
      "trafficSource.campaign\n",
      "trafficSource.keyword\n",
      "trafficSource.medium\n",
      "trafficSource.referralPath\n",
      "trafficSource.source\n",
      "trafficSource.adwordsClickInfo.isVideoAd\n",
      "trafficSource.isTrueDirect\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for col in cat_cols:\n",
    "    print(col)\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(train[col].values.astype('str')) + list(test[col].values.astype('str')))\n",
    "    train[col] = lbl.transform(list(train[col].values.astype('str')))\n",
    "    test[col] = lbl.transform(list(test[col].values.astype('str')))\n",
    "\n",
    "\n",
    "for col in num_cols:\n",
    "    train[col] = train[col].astype(float)\n",
    "    test[col] = test[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = train[train['date']<=20170531]\n",
    "val_df = train[train['date']>20170531]\n",
    "\n",
    "dev_df = dev_df.reset_index()\n",
    "val_df = val_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "class KFoldValidation_non_zero_clf():\n",
    "    def __init__(self, data, n_splits=5):\n",
    "        unique_vis = np.array(sorted(data['fullVisitorId'].astype(str).unique()))\n",
    "        folds = GroupKFold(n_splits)\n",
    "        ids = np.arange(data.shape[0])\n",
    "        \n",
    "        self.fold_ids = []\n",
    "        for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n",
    "            self.fold_ids.append([\n",
    "                    ids[data['fullVisitorId'].astype(str).isin(unique_vis[trn_vis])],\n",
    "                    ids[data['fullVisitorId'].astype(str).isin(unique_vis[val_vis])]\n",
    "                ])\n",
    "            \n",
    "    def validate(self, train, test, features, model, name=\"\", prepare_stacking=False, \n",
    "                 fit_params={\"early_stopping_rounds\": 50, \"verbose\": 100, \"eval_metric\": \"auc\"}):\n",
    "        model.FI = pd.DataFrame(index=features)\n",
    "        full_score = 0\n",
    "        \n",
    "        if prepare_stacking:\n",
    "            test[name] = 0\n",
    "            train[name] = np.NaN\n",
    "        \n",
    "        for fold_id, (trn, val) in enumerate(self.fold_ids):\n",
    "            devel = train[features].iloc[trn]\n",
    "            y_devel = train[\"totals.transactionRevenue\"].iloc[trn] > 0\n",
    "            valid = test[features]\n",
    "            y_valid = test[\"totals.transactionRevenue\"] > 0\n",
    "                       \n",
    "            print(\"Fold \", fold_id, \":\")\n",
    "            if name == \"catclf\" :\n",
    "                model.fit(devel, y_devel, eval_set=[(valid, y_valid)],early_stopping_rounds= 50,verbose= 100)\n",
    "            else :\n",
    "                model.fit(devel, y_devel, eval_set=[(valid, y_valid)], **fit_params)\n",
    "\n",
    "                \n",
    "            \n",
    "            if len(model.feature_importances_) == len(features):  # some bugs in catboost?\n",
    "                model.FI['fold' + str(fold_id)] = model.feature_importances_ / model.feature_importances_.sum()\n",
    "\n",
    "            predictions = model.predict_proba(valid)[:,1]\n",
    "            predictions[predictions < 0] = 0\n",
    "            \n",
    "            val_predictions = model.predict_proba(train[features].iloc[val])[:,1]\n",
    "            val_predictions[val_predictions < 0] = 0\n",
    "            \n",
    "            print(\"Fold \", fold_id, \" error: \", roc_auc_score(y_valid, predictions))\n",
    "            \n",
    "            fold_score = roc_auc_score(y_valid, predictions)\n",
    "            full_score += fold_score / len(self.fold_ids)\n",
    "            print(\"Fold \", fold_id, \" score: \", fold_score)\n",
    "            \n",
    "            if prepare_stacking:\n",
    "                train[name].iloc[val] = val_predictions\n",
    "                \n",
    "                test_predictions = model.predict_proba(test[features])[:,1]\n",
    "                test_predictions[test_predictions < 0] = 0\n",
    "                test[name] += test_predictions / len(self.fold_ids)\n",
    "                \n",
    "        print(\"Final score: \", full_score)\n",
    "        return full_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kfolder_clf = KFoldValidation_non_zero_clf(dev_df,5)\n",
    "\n",
    "\n",
    "\n",
    "lgbmodel_clf = lgb.LGBMClassifier(n_estimators=1000, objective=\"binary\", metric=\"auc\", num_leaves=35, min_child_samples=100,\n",
    "                      learning_rate=0.01, bagging_fraction=0.7, feature_fraction=0.5, bagging_frequency=5, \n",
    "                      bagging_seed=2019, subsample=.9, colsample_bytree=.9, use_best_model=True)\n",
    "\n",
    "Kfolder_clf.validate(dev_df, val_df, num_cols + cat_cols, lgbmodel, \"lgb_zero_clf\", prepare_stacking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def score(data, y):\n",
    "    validation_res = pd.DataFrame(\n",
    "    {\"fullVisitorId\": data[\"fullVisitorId\"].values,\n",
    "     \"transactionRevenue\": data[\"totals.transactionRevenue\"].values,\n",
    "     \"predictedRevenue\": np.expm1(y)})\n",
    "\n",
    "    validation_res = validation_res.groupby(\"fullVisitorId\")[\"transactionRevenue\", \"predictedRevenue\"].sum().reset_index()\n",
    "    return np.sqrt(mean_squared_error(np.log1p(validation_res[\"transactionRevenue\"].values), \n",
    "                                     np.log1p(validation_res[\"predictedRevenue\"].values)))\n",
    "\n",
    "class KFoldValidation():\n",
    "    def __init__(self, data, n_splits=5):\n",
    "        unique_vis = np.array(sorted(data['fullVisitorId'].astype(str).unique()))\n",
    "        folds = GroupKFold(n_splits)\n",
    "        ids = np.arange(data.shape[0])\n",
    "        \n",
    "        self.fold_ids = []\n",
    "        for trn_vis, val_vis in folds.split(X=unique_vis, y=unique_vis, groups=unique_vis):\n",
    "            self.fold_ids.append([\n",
    "                    ids[data['fullVisitorId'].astype(str).isin(unique_vis[trn_vis])],\n",
    "                    ids[data['fullVisitorId'].astype(str).isin(unique_vis[val_vis])]\n",
    "                ])\n",
    "            \n",
    "    def validate(self, train, test, features, model, name=\"\", prepare_stacking=False, \n",
    "                 fit_params={\"early_stopping_rounds\": 50, \"verbose\": 100, \"eval_metric\": \"rmse\"}):\n",
    "        model.FI = pd.DataFrame(index=features)\n",
    "        full_score = 0\n",
    "        \n",
    "        if prepare_stacking:\n",
    "            test[name] = 0\n",
    "            train[name] = np.NaN\n",
    "        \n",
    "        for fold_id, (trn, val) in enumerate(self.fold_ids):\n",
    "            devel = train[features].iloc[trn]\n",
    "            y_devel = np.log1p(train[\"totals.transactionRevenue\"].iloc[trn])\n",
    "            valid = test[features]\n",
    "            y_valid = np.log1p(test[\"totals.transactionRevenue\"])\n",
    "                       \n",
    "            print(\"Fold \", fold_id, \":\")\n",
    "            model.fit(devel, y_devel, eval_set=[(valid, y_valid)], **fit_params)\n",
    "\n",
    "            if len(model.feature_importances_) == len(features):  # some bugs in catboost?\n",
    "                model.FI['fold' + str(fold_id)] = model.feature_importances_ / model.feature_importances_.sum()\n",
    "\n",
    "            predictions = model.predict(valid)\n",
    "            predictions[predictions < 0] = 0\n",
    "            \n",
    "            val_predictions = model.predict(train[features].iloc[val])\n",
    "            val_predictions[val_predictions < 0] = 0\n",
    "            \n",
    "            print(\"Fold \", fold_id, \" error: \", mean_squared_error(y_valid, predictions)**0.5)\n",
    "            \n",
    "            fold_score = score(test, predictions)\n",
    "            full_score += fold_score / len(self.fold_ids)\n",
    "            print(\"Fold \", fold_id, \" score: \", fold_score)\n",
    "            \n",
    "            \n",
    "            \n",
    "            if prepare_stacking:\n",
    "                train[name].iloc[val] = val_predictions\n",
    "                \n",
    "                test_predictions = model.predict(test[features])\n",
    "                test_predictions[test_predictions < 0] = 0\n",
    "                test[name] += test_predictions / len(self.fold_ids)\n",
    "                test[\"prediction_\"+str(fold_id)] = model.predict(test[features])\n",
    "                \n",
    "        print(\"Final score: \", full_score)\n",
    "        return full_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kfolder = KFoldValidation(dev_df,5)\n",
    "\n",
    "\n",
    "\n",
    "lgbmodel = lgb.LGBMRegressor(n_estimators=1000, objective=\"regression\", metric=\"rmse\", num_leaves=11, min_child_samples=100,\n",
    "                      learning_rate=0.02, bagging_fraction=0.7, feature_fraction=0.5, bagging_frequency=5, \n",
    "                      bagging_seed=2019, subsample=.9, colsample_bytree=.9, use_best_model=True)\n",
    "\n",
    "Kfolder.validate(dev_df, val_df, num_cols + cat_cols, lgbmodel, \"lgbpred\", prepare_stacking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
